<h1 align="center">PreCog LLM Workshop</h1>
<p align="center"><i>Code, Documentation to follow along with the workshop. </i></p>

- Run the notebooks that need GPU (high compute) on Google Colab/Kaggle Notebooks.
- Create new issue if you need help with anything (even prior or after the workshop). A sample issue is created.
- We have created a bunch of assignments for you to try things and submit - and will be introducing them along the workshop.
- Your feedback will help us improve material presented during the workshop. Fill in [this Form (takes ~4 mins)](https://forms.office.com/r/2xPT7D7P0G)
- Once you are done with the assignments, create a github repo with all the necessary files, make the repo public and fill in [this form (takes ~4 mins](https://forms.office.com/r/puwCBbFq5V). 


# Session 1 - LLM Capabilities(./Session1)

# [Session 2 - LLMs in depth](./Session2) 

# Session 3 - Using LLMs - Open-Source and Commercial APIs
- [Commercial APIs](./Session3/commercial_llm_apis.ipynb)
- [Open-Source LLMs for Inference on GPUs](./Session3/generation_with_opensource_LLMs.ipynb) (Run on GoogleColab or similar services)
- [Open-Source LLMs fine-tuning on GPUs](./Session3/fine-tuning-llms.ipynb) (Run on GoogleColab or similar services)
- [Open-Source LLMs on Local Machines (Laptop/PCs) using Ollama](./Session3/ollama.md)
- [LLM Apps using LangChain and Ollama](./Session3/langchainpy_with_ollama.md)
- [LLM Apps with Frontend using LangChain + Ollama + Streamlit](./Session3/LLMAppWIthFrontEnd)
